{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DA_sentiment_analysis.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZgNwNNEO_e7u"},"source":["# Mount google drive"]},{"cell_type":"code","metadata":{"id":"vJ6BR33t_V2C"},"source":["from google.colab import drive\n","drive.mount('drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JLRP4DGQAYV8"},"source":["#Import required libraries"]},{"cell_type":"markdown","metadata":{"id":"_8UrC8KYCKmC"},"source":[""]},{"cell_type":"code","metadata":{"id":"C5PWTB2QQMAk"},"source":["! pip install nltk\n","! pip install wordcloud"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Em3-XDqCAhHD"},"source":["# General packages\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import os\n","\n","# NLP packages\n","import nltk\n","from nltk import word_tokenize\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from collections import Counter\n","from wordcloud import WordCloud\n","\n","# Modeling packages\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","\n","from pylab import rcParams\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","rcParams['figure.figsize'] = 14, 6\n","plt.style.use('ggplot')\n","import re\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QpphN2H0AwS7"},"source":["# Read data from drive"]},{"cell_type":"code","metadata":{"id":"MWpwC1bIA014"},"source":["amazon_reviews = pd.read_csv(\"/content/drive/MyDrive/Colab-Data Science/DataSets/amazonProductReviews.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-BuMEiJuBN2n"},"source":["amazon_reviews.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SjZQfmJqqTkk"},"source":["# Understanding the data"]},{"cell_type":"code","metadata":{"id":"V8a9HqIyQ8oG"},"source":["## Getting the number of words by splitting them by a space\n","words_per_review = amazon_reviews.review_comments.apply(lambda x: len(x.split(\" \")))\n","words_per_review.hist(bins = 50)\n","plt.xlabel('Review Length (words)')\n","plt.ylabel('Frequency')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8iUHGnVpRZ_l"},"source":["print('Average words:', words_per_review.mean())\n","print('Skewness:', words_per_review.skew())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uY3wYNRUvRvv"},"source":["# Extract rating points from review_ratings\n","r=r'^\\D*(\\d+)'\n","amazon_reviews[\"points\"]= amazon_reviews[\"review_ratings\"].str.extract(r)\n","amazon_reviews = amazon_reviews.astype({\"points\": int})\n","amazon_reviews.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S9E9kVrlwvCg"},"source":["# Derive Tag feature w.r.t points \n","amazon_reviews.loc[(amazon_reviews['points'] == 1) | (amazon_reviews['points'] == 2), 'Tag'] = -1 #'Negative'\n","amazon_reviews.loc[(amazon_reviews['points'] == 3), 'Tag'] = 0 #'Neutral'  \n","amazon_reviews.loc[(amazon_reviews['points'] == 4)| (amazon_reviews['points'] == 5), 'Tag'] = 1 #'Positive'\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DnPx0_6X083H"},"source":["# The data distribution with respect to points \n","amazon_reviews.value_counts(\"Tag\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ub8i_tvTxJ2K"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EVhlXjMbTJm2"},"source":["# The data distribution with respect to points %\n","percent_val = 100 * amazon_reviews['Tag'].value_counts()/len(amazon_reviews)\n","percent_val"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cZyIdP2UVD_l"},"source":["percent_val.plot.bar()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5nPY6-g3Vt-R"},"source":["# Text Visualization \n","word_cloud_text = ''.join(amazon_reviews['review_comments'])\n","\n","wordcloud = WordCloud(max_font_size=100, # Maximum font size for the largest word\n","                      max_words=100, # The maximum number of words\n","                      background_color=\"white\", # Background color for the word cloud image\n","                      scale = 10, # Scaling between computation and drawing\n","                      width=800, # Width of the canvas\n","                      height=400 # Height of the canvas\n","                     ).generate(word_cloud_text)\n","\n","plt.figure()\n","plt.imshow(wordcloud, \n","           interpolation=\"bilinear\") # to make the displayed image appear more smoothly\n","plt.axis(\"off\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i6fsVuxbIvas"},"source":["# Preprocessings - Converts to lower-case, removes square bracket, removes numbers and punctuation"]},{"cell_type":"code","metadata":{"id":"Z7vSHkaDXwAH"},"source":["amazon_reviews.head(3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0a7JBm9nKdLw"},"source":["amazon_reviews.drop(columns = ['id', 'review_titles', 'review_ratings','points','reviewer'], inplace = True)\n","amazon_reviews.to_csv('../content/drive/MyDrive/Colab-Data Science/DataSets/review_silverAnalysis.csv', index = True)\n","\n","amazon_reviews.head(3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MiXn-zS8WwGa"},"source":["amazon_reviews.Tag.value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rDZzdylmW7eQ"},"source":["# Loading golden analysis data\n","#amazon_reviews = pd.read_csv(\"/content/drive/MyDrive/Colab-Data Science/DataSets/review_gold_Analysis.csv\")\n","#amazon_reviews.Tag.value_counts()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T4vGS9Jywh78"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EdWw2TmiXsnU"},"source":["amazon_reviews['reviews_text_new'] = amazon_reviews['review_comments'].str.lower()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vJHnJKoIalfD"},"source":["from nltk import word_tokenize\n","nltk.download('punkt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GSuGJCOXYcId"},"source":["# Tokenization\n","token_lists = [word_tokenize(each) for each in amazon_reviews['review_comments']]\n","tokens = [item for sublist in token_lists for item in sublist]\n","print(\" Total token before lowercase: \",len(set(tokens)))\n","\n","# For reviews converted to lowe case\n","token_lists_lower = [word_tokenize(each) for each in amazon_reviews['reviews_text_new']]\n","tokens_lower = [item for sublist in token_lists_lower for item in sublist]\n","print(\" After token before lowercase: \",len(set(tokens_lower)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DJT2iwP0bID6"},"source":["#Removing special character\n","spl_chars = amazon_reviews['reviews_text_new'].apply(lambda review:[char for char in list(review) if not char.isalnum() and char != ' '])\n","\n","## Making single list for special character\n","special_char_list = [item for sublist in spl_chars for item in sublist]\n","\n","# distinct special characters\n","len(set(special_char_list))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jl_NWYKAcA2V"},"source":["review_backup = amazon_reviews['reviews_text_new'].copy()\n","amazon_reviews['reviews_text_new'] = amazon_reviews['reviews_text_new'].str.replace(r'[^A-Za-z0-9 ]+', ' ')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cc_p0fQabH7G"},"source":["token_lists = [word_tokenize(each) for each in amazon_reviews['reviews_text_new']]\n","tokens = [item for sublist in token_lists for item in sublist]\n","print(\"Number of unique tokens now: \",len(set(tokens)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bJds5_6ldLj9"},"source":["#Stopwords and high/low frequency words"]},{"cell_type":"code","metadata":{"id":"6IYkbsw4dOIs"},"source":["nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","noise_words = []\n","eng_stop_words = stopwords.words('english')\n","eng_stop_words"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VmzZaGMleOty"},"source":["stop_words = set(eng_stop_words)\n","without_stop_words = []\n","stopword = []\n","sentence = amazon_reviews['reviews_text_new'][0]\n","words = nltk.word_tokenize(sentence)\n","\n","for word in words:\n","    if word in stop_words:\n","        stopword.append(word)\n","    else:\n","        without_stop_words.append(word)\n","\n","print('-- Original Sentence --\\n', sentence)\n","print('\\n-- Stopwords in the sentence --\\n', stopword)\n","print('\\n-- Non-stopwords in the sentence --\\n', without_stop_words)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fVd5JiGWdgml"},"source":["# Remove Stopwords\n","def stopwords_removal(stop_words, sentence):\n","    return [word for word in nltk.word_tokenize(sentence) if word not in stop_words]\n","\n","amazon_reviews['reviews_text_nonstop'] = amazon_reviews['reviews_text_new'].apply(lambda row: stopwords_removal(stop_words, row))\n","amazon_reviews.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zE5SvJ_1esOJ"},"source":["#Stemming & lemmatization"]},{"cell_type":"code","metadata":{"id":"Y1zVUiCjem3I"},"source":["from nltk.stem import PorterStemmer, LancasterStemmer # Common stemmers\n","from nltk.stem import WordNetLemmatizer # Common Lematizer\n","nltk.download('wordnet')\n","from nltk.corpus import wordnet\n","\n","porter = PorterStemmer()\n","lancaster = LancasterStemmer()\n","lemmatizer = WordNetLemmatizer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tm0h0PKSfUJk"},"source":["print(\"Lancaster Stemmer\")\n","print(lancaster.stem(\"trouble\"))\n","print(lancaster.stem(\"troubling\"))\n","print(lancaster.stem(\"troubled\"))\n","\n","# Provide a word to be lemmatized\n","print(\"WordNet Lemmatizer\")\n","print(lemmatizer.lemmatize(\"trouble\", wordnet.NOUN))\n","print(lemmatizer.lemmatize(\"troubling\", wordnet.VERB))\n","print(lemmatizer.lemmatize(\"troubled\", wordnet.VERB))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uHUBf5Bof8UQ"},"source":["#Model training with BOW"]},{"cell_type":"code","metadata":{"id":"tJArGUjjfmQx"},"source":["# The following code creates a word-document matrix.\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","vec = CountVectorizer()\n","X = vec.fit_transform(amazon_reviews['reviews_text_new'])\n","df = pd.DataFrame(X.toarray(), columns = vec.get_feature_names())\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3DjB8XnWg3tG"},"source":["bow_counts = CountVectorizer(tokenizer= word_tokenize, # type of tokenization\n","                             stop_words=noise_words, # List of stopwords\n","                             ngram_range=(1,1)) # number of n-grams\n","\n","bow_data = bow_counts.fit_transform(amazon_reviews['reviews_text_new'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ur004X9lg5h4"},"source":["bow_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uBOQlUJlhcll"},"source":["X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(bow_data, # Features\n","                                                                    amazon_reviews['Tag'], # Target variable\n","                                                                    test_size = 0.2, # 20% test size\n","                                                                    random_state = 0) # random state for replication purposes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oj-3x20lhm1y"},"source":["y_test_bow.value_counts()/y_test_bow.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AjdFt287iRX0"},"source":["#Applying logistic regression\n","lr_model_all = LogisticRegression() # Logistic regression\n","lr_model_all.fit(X_train_bow, y_train_bow) # Fitting a logistic regression model\n","\n","from sklearn.metrics import confusion_matrix\n","predictions = lr_model_all.predict(X_test_bow)\n","confusion_matrix(predictions, y_test_bow)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1nep-ADqhsMA"},"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score\n","\n","print(\"Accuracy : \", accuracy_score(predictions, y_test_bow))\n","print(\"Precision : \", precision_score(predictions, y_test_bow, average = 'weighted'))\n","print(\"Recall : \", recall_score(predictions, y_test_bow, average = 'weighted'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c-vBSeDcTgsN"},"source":["#Model training with TF-IDF"]},{"cell_type":"code","metadata":{"id":"K24LvpaUjNw3"},"source":["amazon_reviews.head(2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FFlvVsKITjgc"},"source":["from sklearn.model_selection import train_test_split\n","\n","iv = amazon_reviews.reviews_text_new \t\n","dv = amazon_reviews.Tag\n","\n","IV_train, IV_test, DV_train, DV_test = train_test_split(iv, dv, test_size = 0.2, random_state = 225)\n","\n","print('IV_train :', len(IV_train))\n","print('IV_test  :', len(IV_test))\n","print('DV_train :', len(DV_train))\n","print('DV_test  :', len(DV_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YjWxn99fUIUs"},"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","tvec = TfidfVectorizer(use_idf=True,norm='l2',smooth_idf=True)\n","\n","from sklearn.linear_model import LogisticRegressionCV\n","model = LogisticRegressionCV(cv=10,scoring='accuracy',random_state=0,n_jobs=-1,verbose=3,max_iter=300,solver='newton-cg',multi_class='multinomial')\n","\n","# from sklearn import svm\n","# model = svm.SVC(decision_function_shape='ovo')\n","\n","# from sklearn.ensemble import AdaBoostClassifier\n","# model = AdaBoostClassifier()\n","\n","# from sklearn.naive_bayes import MultinomialNB\n","# model = MultinomialNB()\n","\n","# from xgboost import  XGBClassifier\n","# model = XGBClassifier(eta=.01,alpha=50) \n","\n","# from sklearn.ensemble import RandomForestClassifier\n","# model = RandomForestClassifier(n_estimators=20, n_jobs=-1)\n","\n","# from sklearn import svm\n","# model = svm.SVC(decision_function_shape='ovo')\n","\n","from sklearn.pipeline import Pipeline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8r0lnTFBUuk0"},"source":["model = Pipeline([('vectorizer',tvec),('classifier',model)])\n","model.fit(IV_train, DV_train)\n","from sklearn.metrics import confusion_matrix\n","\n","predictions = model.predict(IV_test)\n","confusion_matrix(predictions, DV_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gouw1lEbVLD9"},"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score\n","\n","print(\"Accuracy : \", accuracy_score(predictions, DV_test))\n","print(\"Precision : \", precision_score(predictions, DV_test, average = 'weighted'))\n","print(\"Recall : \", recall_score(predictions, DV_test, average = 'weighted'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TMXDLDfkjpZS"},"source":["#import pickle\n","#pickle.dump(model,open('/content/drive/MyDrive/Colab-Data Science/DataSets/model.pkl','wb'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LtHiASKLVs7Y"},"source":["#Testing Custome review"]},{"cell_type":"code","metadata":{"id":"tNmXn9UzVsIr"},"source":["\n","\n","example = [\"The battery life is so bad\"]\n","result = model.predict(example)\n","\n","print(model.predict_proba(example)[0])\n","print(\" Negative(-1)={}\".format(model.predict_proba(example)[0][0]))\n","print(\" Neutral(0)={}\".format(model.predict_proba(example)[0][1]))\n","print(\" Positive(1)={}\".format(model.predict_proba(example)[0][2]))\n","\n","if result==0:\n","  print(\"Neutral\")\n","elif result==1:\n","  print(\"Positive\")\n","else:\n","  print(\"Negative\")"],"execution_count":null,"outputs":[]}]}